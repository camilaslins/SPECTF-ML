{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f618fcba",
   "metadata": {},
   "source": [
    "Importação de bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e25b27d-aa93-41e9-b7e3-865f9767c481",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import random\n",
    "import statistics as st\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3205fc86",
   "metadata": {},
   "source": [
    "Classe para treinar e criar um classificador bayesiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a694d056",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierTrainer:\n",
    "    # inicialização da classificação\n",
    "    def __init__(self, datasets, model):\n",
    "        self.datasets = datasets\n",
    "        self.model = model\n",
    "    \n",
    "    def build_pipeline(self):\n",
    "        # função para criar o pipeline\n",
    "        #esse pipeline consiste em um escalador (StandardScaler) para transformar os valores entre 0 e 1\n",
    "        # seguido pelo classificador (self.model).\n",
    "        return Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('clf', self.model)\n",
    "        ])\n",
    "\n",
    "    def find_majority_and_choose_random(self, row):\n",
    "        #identifica a classe com a estimativa de maxima verossimilhança\n",
    "        # se existirem 2 classes com a mesma probabilidade retorna de forma aleatória\n",
    "        counts = Counter(row)\n",
    "        max_count = max(counts.values())\n",
    "        majority_numbers = [num for num, count in counts.items() if count == max_count]\n",
    "        return random.choice(majority_numbers) if len(majority_numbers) > 1 else majority_numbers[0]\n",
    "\n",
    "    def find_majority_numbers(self, matrix):\n",
    "        #as predições foram salvas em uma matriz \n",
    "        majority= []\n",
    "        for row in matrix:\n",
    "            #cada linha possui a classificação salva em um vetor ex.: [[1],[0]]\n",
    "            # a função find_majority_and_choose_random recebe uma predição e \n",
    "            majority.append(self.find_majority_and_choose_random(row))\n",
    "        return majority\n",
    "\n",
    "    # treina o classificador para várias iterações, com diferentes partições do conjunto de dados realizando 30 iterações\n",
    "    def train_classifiers_with_random_states(self, n_iterations=30):\n",
    "        #inicia as métricas como vetores vazios\n",
    "        precision_scores, recall_scores, f1_scores, accuracy_scores = [], [], [], []\n",
    "        #total de linhas do dataset\n",
    "        total_rows = len(self.datasets)\n",
    "        #classes do dataset (estão salvos na coluna diagnosis)\n",
    "        labels = self.datasets['diagnosis']\n",
    "        #realiza a divisão em treino e teste e realiza a classificação e validação das métricas 30x\n",
    "        for _ in tqdm(range(n_iterations)):\n",
    "            #escolhe os índices aleatoriamente para separar os dados em treino e teste(20% e 80%)\n",
    "            #além disso utilizei o parâmetro stratify=labels que garante que a distribuição das classes (rótulos) seja similar nos conjuntos de treinamento e teste.\n",
    "            train_indices, test_indices = train_test_split(np.arange(total_rows), test_size=0.2, random_state=None, stratify=labels)\n",
    "            #divide o dataset em treino e teste  \n",
    "            train_data, test_data = self.datasets.iloc[train_indices], self.datasets.iloc[test_indices]\n",
    "            #divide os dados de treino e teste em X e Y, onde X são os atributos e y a classe \n",
    "            #no caso desse projeto a classe é diagnosis podendo ser 0 ou 1 \n",
    "            X_train, y_train = train_data.drop('diagnosis', axis=1), train_data['diagnosis']\n",
    "            X_test, y_test = test_data.drop('diagnosis', axis=1), test_data['diagnosis']\n",
    "            # Escalar os dados\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "            \n",
    "            #chama a função build_pipeline para execução do pipeline, \n",
    "            # sequência de etapas de processamento de dados e treinamento de modelo\n",
    "            pipeline = self.build_pipeline()\n",
    "            #cálculo das médias e das variancias para cada uma das classes \n",
    "            pipeline.fit(X_train, y_train)\n",
    "            #Realiza a predição para o conjunto de teste.\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "            #salva as predições em um vetor \n",
    "\n",
    "            #métricas de precision, recall, f1 e acurácia\n",
    "            precision_scores.append(precision_score(y_test, y_pred, average='weighted'))\n",
    "            recall_scores.append(recall_score(y_test, y_pred, average='weighted'))\n",
    "            f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "            accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "        \n",
    "        self.print_metrics(precision_scores, recall_scores, f1_scores, accuracy_scores, y_test, y_pred)\n",
    "\n",
    "    def print_metrics(self, precision_scores, recall_scores, f1_scores, accuracy_scores, y_test, y_pred):\n",
    "        print(f\"Precision Mean: {st.mean(precision_scores)}, Std Dev: {st.stdev(precision_scores)}, CI: {np.percentile(precision_scores, [2.5, 97.5])}\")\n",
    "        print(f\"Recall Mean: {st.mean(recall_scores)}, Std Dev: {st.stdev(recall_scores)}, CI: {np.percentile(recall_scores, [2.5, 97.5])}\")\n",
    "        print(f\"F1 Mean: {st.mean(f1_scores)}, Std Dev: {st.stdev(f1_scores)}, CI: {np.percentile(f1_scores, [2.5, 97.5])}\")\n",
    "        print(f\"Accuracy Mean: {st.mean(accuracy_scores)}, Std Dev: {st.stdev(accuracy_scores)}, CI: {np.percentile(accuracy_scores, [2.5, 97.5])}\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00a71b9",
   "metadata": {},
   "source": [
    "Importar os datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd1e8bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectf_heart = fetch_ucirepo(id=96)\n",
    "\n",
    "# data (as pandas dataframes)\n",
    "X = spectf_heart.data.features\n",
    "y = spectf_heart.data.targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce7c9cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1R</th>\n",
       "      <th>F1S</th>\n",
       "      <th>F2R</th>\n",
       "      <th>F2S</th>\n",
       "      <th>F3R</th>\n",
       "      <th>F3S</th>\n",
       "      <th>F4R</th>\n",
       "      <th>F4S</th>\n",
       "      <th>F5R</th>\n",
       "      <th>F5S</th>\n",
       "      <th>...</th>\n",
       "      <th>F18R</th>\n",
       "      <th>F18S</th>\n",
       "      <th>F19R</th>\n",
       "      <th>F19S</th>\n",
       "      <th>F20R</th>\n",
       "      <th>F20S</th>\n",
       "      <th>F21R</th>\n",
       "      <th>F21S</th>\n",
       "      <th>F22R</th>\n",
       "      <th>F22S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>52</td>\n",
       "      <td>70</td>\n",
       "      <td>67</td>\n",
       "      <td>73</td>\n",
       "      <td>66</td>\n",
       "      <td>72</td>\n",
       "      <td>61</td>\n",
       "      <td>58</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>66</td>\n",
       "      <td>56</td>\n",
       "      <td>62</td>\n",
       "      <td>56</td>\n",
       "      <td>72</td>\n",
       "      <td>62</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>64</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72</td>\n",
       "      <td>62</td>\n",
       "      <td>69</td>\n",
       "      <td>67</td>\n",
       "      <td>78</td>\n",
       "      <td>82</td>\n",
       "      <td>74</td>\n",
       "      <td>65</td>\n",
       "      <td>69</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>71</td>\n",
       "      <td>63</td>\n",
       "      <td>60</td>\n",
       "      <td>69</td>\n",
       "      <td>73</td>\n",
       "      <td>67</td>\n",
       "      <td>71</td>\n",
       "      <td>56</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71</td>\n",
       "      <td>62</td>\n",
       "      <td>70</td>\n",
       "      <td>64</td>\n",
       "      <td>67</td>\n",
       "      <td>64</td>\n",
       "      <td>79</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>70</td>\n",
       "      <td>66</td>\n",
       "      <td>65</td>\n",
       "      <td>64</td>\n",
       "      <td>55</td>\n",
       "      <td>61</td>\n",
       "      <td>41</td>\n",
       "      <td>51</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69</td>\n",
       "      <td>71</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>61</td>\n",
       "      <td>63</td>\n",
       "      <td>67</td>\n",
       "      <td>65</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>66</td>\n",
       "      <td>65</td>\n",
       "      <td>72</td>\n",
       "      <td>73</td>\n",
       "      <td>68</td>\n",
       "      <td>68</td>\n",
       "      <td>59</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>66</td>\n",
       "      <td>61</td>\n",
       "      <td>66</td>\n",
       "      <td>61</td>\n",
       "      <td>58</td>\n",
       "      <td>69</td>\n",
       "      <td>69</td>\n",
       "      <td>72</td>\n",
       "      <td>68</td>\n",
       "      <td>...</td>\n",
       "      <td>67</td>\n",
       "      <td>69</td>\n",
       "      <td>70</td>\n",
       "      <td>66</td>\n",
       "      <td>70</td>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>55</td>\n",
       "      <td>49</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   F1R  F1S  F2R  F2S  F3R  F3S  F4R  F4S  F5R  F5S  ...  F18R  F18S  F19R  \\\n",
       "0   59   52   70   67   73   66   72   61   58   52  ...    66    56    62   \n",
       "1   72   62   69   67   78   82   74   65   69   63  ...    65    71    63   \n",
       "2   71   62   70   64   67   64   79   65   70   69  ...    73    70    66   \n",
       "3   69   71   70   78   61   63   67   65   59   59  ...    61    61    66   \n",
       "4   70   66   61   66   61   58   69   69   72   68  ...    67    69    70   \n",
       "\n",
       "   F19S  F20R  F20S  F21R  F21S  F22R  F22S  \n",
       "0    56    72    62    74    74    64    67  \n",
       "1    60    69    73    67    71    56    58  \n",
       "2    65    64    55    61    41    51    46  \n",
       "3    65    72    73    68    68    59    63  \n",
       "4    66    70    64    60    55    49    41  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22ee0364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis\n",
       "0          1\n",
       "1          1\n",
       "2          1\n",
       "3          1\n",
       "4          1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20838ff8-7326-4ac3-bd9d-4edff999e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X.copy()\n",
    "df['diagnosis'] = y['diagnosis'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38b5a2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['F1R', 'F1S', 'F2R', 'F2S', 'F3R', 'F3S', 'F4R', 'F4S', 'F5R', 'F5S',\n",
       "       'F6R', 'F6S', 'F7R', 'F7S', 'F8R', 'F8S', 'F9R', 'F9S', 'F10R', 'F10S',\n",
       "       'F11R', 'F11S', 'F12R', 'F12S', 'F13R', 'F13S', 'F14R', 'F14S', 'F15R',\n",
       "       'F15S', 'F16R', 'F16S', 'F17R', 'F17S', 'F18R', 'F18S', 'F19R', 'F19S',\n",
       "       'F20R', 'F20S', 'F21R', 'F21S', 'F22R', 'F22S', 'diagnosis'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1381a4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a74e48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diagnosis\n",
       "1    212\n",
       "0     55\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8166dd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Classe do Classificador Bayesiano Gaussiano com Covariância Completa\n",
    "class GaussianBayes:\n",
    "    def __init__(self):\n",
    "        self.class_priors = {}  # P(\\omega_i)\n",
    "        self.means = {}         # μ para cada classe\n",
    "        self.covariances = {}   # Matriz de covariância para cada classe\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Treina o modelo calculando os parâmetros (máxima verossimilhança).\n",
    "        \"\"\"\n",
    "        self.classes = np.unique(y)\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]  # Dados da classe c\n",
    "            self.class_priors[c] = len(X_c) / len(X)  # Prior P(\\omega_i)\n",
    "            self.means[c] = X_c.mean(axis=0)  # Vetor de médias para a classe c\n",
    "            eps = 1e-5  # Regularização\n",
    "            self.covariances[c] = np.diag(np.var(X_c, axis=0) + eps)\n",
    "\n",
    "    def _multivariate_gaussian(self, x, mean, covariance):\n",
    "        \"\"\"\n",
    "        Calcula a verossimilhança p(x_k | ω_i) usando a densidade multivariada Gaussiana.\n",
    "        \"\"\"\n",
    "        d = len(x)  # Dimensão do vetor de características\n",
    "        covariance_det = np.linalg.det(covariance)\n",
    "        if covariance_det <= 0:  # Verifica problemas de singularidade\n",
    "            raise ValueError(f\"Determinante da matriz de covariância é inválido: {covariance_det}\")\n",
    "        \n",
    "        covariance_inv = np.linalg.inv(covariance)\n",
    "\n",
    "        # Termo de normalização\n",
    "        normalization = (2 * np.pi) ** (-d / 2) * (covariance_det ** -0.5)\n",
    "\n",
    "\n",
    "        # Termo exponencial\n",
    "        diff = x - mean\n",
    "        exponent = -0.5 * diff.T @ covariance_inv @ diff\n",
    "\n",
    "        return normalization * np.exp(exponent)\n",
    "\n",
    "    def _posterior(self, x):\n",
    "        \"\"\"\n",
    "        Calcula as probabilidades a posteriori P(\\omega_i | x_k) para cada classe.\n",
    "        \"\"\"\n",
    "        posteriors = {}\n",
    "        for c in self.classes:\n",
    "            likelihood = self._multivariate_gaussian(x, self.means[c], self.covariances[c])\n",
    "            posterior = likelihood * self.class_priors[c]\n",
    "            posteriors[c] = posterior\n",
    "        return posteriors\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Prediz a classe para cada exemplo no conjunto X.\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            posteriors = self._posterior(x)\n",
    "            predictions.append(max(posteriors, key=posteriors.get))  # Classe com maior P(\\omega_i | x_k)\n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3c2030e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:04<00:00,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Mean: 0.8477344164193825, Std Dev: 0.03079161533091068, CI: [0.78776495 0.8907768 ]\n",
      "Recall Mean: 0.6833333333333333, Std Dev: 0.06119716067219918, CI: [0.57407407 0.77777778]\n",
      "F1 Mean: 0.7125729421822118, Std Dev: 0.05644638885533776, CI: [0.61152037 0.79818133]\n",
      "Accuracy Mean: 0.6833333333333333, Std Dev: 0.06119716067219918, CI: [0.57407407 0.77777778]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.91      0.56        11\n",
      "           1       0.97      0.65      0.78        43\n",
      "\n",
      "    accuracy                           0.70        54\n",
      "   macro avg       0.68      0.78      0.67        54\n",
      "weighted avg       0.85      0.70      0.73        54\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# treinando um classificador bayesiano\n",
    "model = GaussianBayes() \n",
    "#inicializando um classificador com a nossa base df e o modelo escolhido \n",
    "trainer = ClassifierTrainer(df, model=model)\n",
    "#realizando o treino e teste nos dados para o classificador trainer, usando 30 partições\n",
    "trainer.train_classifiers_with_random_states(n_iterations=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
